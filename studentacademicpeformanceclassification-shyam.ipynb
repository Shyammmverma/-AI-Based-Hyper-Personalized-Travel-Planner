{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":407679,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Automatically download the dataset to your Kaggle environment.\n \nPrint the file path where the dataset is saved, which you can then use to load it into a DataFrame.","metadata":{}},{"cell_type":"code","source":"import kagglehub\n \n# Download latest version\npath = kagglehub.A(\"uciml/student-alcohol-consumption\")\n \nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import Libraries and Load Data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n \nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n \n# Load data\ndf = pd.read_csv('/kaggle/input/student-alcohol-consumption/student-mat.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T03:11:27.367002Z","iopub.status.idle":"2025-06-27T03:11:27.367373Z","shell.execute_reply.started":"2025-06-27T03:11:27.367186Z","shell.execute_reply":"2025-06-27T03:11:27.367205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Import essential Python libraries for data analysis, visualization, and machine learning.\n- Load the Student Alcohol Consumption dataset using pandas.\n \nThe dataset student-mat.csv contains information about students’ academic performance and alcohol consumption. This will help us explore behavioral patterns and predict outcomes using classification models.","metadata":{}},{"cell_type":"code","source":"# Create the Target Variable\n# Create binary label\ndf['high_grade'] = (df['G3'] >= 10).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T03:16:34.465983Z","iopub.status.idle":"2025-06-27T03:16:34.466377Z","shell.execute_reply.started":"2025-06-27T03:16:34.466223Z","shell.execute_reply":"2025-06-27T03:16:34.466240Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To prepare the data for classification, we created a new binary target variable called high_grade:\n \n- Students with a final grade (G3) greater than or equal to 10 are labeled as 1 (high performance).\n- Students with a grade below 10 are labeled as 0 (low performance).","metadata":{}},{"cell_type":"code","source":"import kagglehub\n \n# Download latest version\npath = kagglehub.A(\"uciml/student-alcohol-consumption\")\n \nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dropped G1,G2, and G3: These are earlier and final grades that directly impact the target (`high_grade`), so we removed them to prevent data leakage.\n- Encoded categorical variables using one-hot encoding with drop_first=True to avoid multicollinearity and convert categorical features into numerical format.","metadata":{}},{"cell_type":"code","source":"# Modeling\n# Train a few classifiers\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Decision Tree\": DecisionTreeClassifier()\n}\n \nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f\"\\n{name} Results:\")\n    print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Logistic Regression: A linear model suitable for binary classification problems.\n- Random Forest Classifier: An ensemble method using multiple decision trees for improved accuracy and robustness.\n- Decision Tree Classifier: A simple, interpretable tree-based model.","metadata":{}},{"cell_type":"code","source":"# Hyperparameter Tuning\n# Tune Random Forest\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, 15]\n}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1')\ngrid.fit(X_train, y_train)\nprint(\"Best Params:\", grid.best_params_)\nprint(\"Best F1 Score:\", grid.best_score_)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- n_estimators: Number of trees in the forest → tested values: 50, 100, 200\n- max_depth: Maximum depth of each tree → tested values: 5, 10, 15\n \nKey details:\n- Cross-validation: 5-fold (`cv=5`) to ensure reliable performance estimates\n- Scoring metric: F1 Score, which balances precision and recall","metadata":{}},{"cell_type":"markdown","source":"Final Comparison & Reflection\n \nModel Performance Comparison\n \nAfter training and evaluating three models — Logistic Regression, Decision Tree, and \nRandom Forest — we compared their results based on key classification metrics (Precision, Recall, F1-Score, and Accuracy):\n \n- Logistic Regression offered solid baseline performance with high interpretability, especially useful when transparency is important.\n- Decision Tree provided clear decision rules but tended to overfit on training data, showing slightly lower generalization performance.\n- Random Forest, especially after hyperparameter tuning, achieved the highest F1-score, indicating the best balance between precision and recall.\n \nRecommended Model\n \nRandom Forest Classifier is recommended for deployment in a school analytics tool due to the following reasons:\n \n- Strong performance across all evaluation metrics, especially after tuning.\n- Robustness to noise and overfitting thanks to ensemble learning.\n- Feature importance insights that can help educators understand key predictors of student success.\n- ]Scalability to work on larger or more complex datasets if extended in the future.\n \nReflection\n \nBuilding this classification pipeline offered valuable hands-on experience with:\n \n- Real-world education-related data\n- End-to-end machine learning workflow\n- Trade-offs between interpretability and performance\n \nBy using such models, schools can better identify students at academic risk early and target interventions more effectively.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport pandas as pd\n \n# Assuming models dict and predictions from before, recompute metrics on test set\nmodel_metrics = {}\n \nfor name, model in models.items():\n    y_pred = model.predict(X_test)\n    model_metrics[name] = {\n        \"Accuracy\": accuracy_score(y_test, y_pred),\n        \"Precision\": precision_score(y_test, y_pred),\n        \"Recall\": recall_score(y_test, y_pred),\n        \"F1 Score\": f1_score(y_test, y_pred)\n    }\n \n# Create DataFrame for easy viewing\nmetrics_df = pd.DataFrame(model_metrics).T\nmetrics_df = metrics_df.round(3)\n \nprint(\"Evaluation Metrics Comparison:\")\nprint(metrics_df)\n \n# Plot F1 scores for visual comparison\nplt.figure(figsize=(8,5))\nmetrics_df[\"F1 Score\"].plot(kind='bar', color=['skyblue', 'lightgreen', 'salmon'])\nplt.title('Model Comparison: F1 Scores')\nplt.ylabel('F1 Score')\nplt.ylim(0, 1)\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" \nFinal Reflection\n \nThis project demonstrates the importance of:\n \n- Careful preprocessing and feature engineering\n- Model selection and hyperparameter tuning\n- Balancing interpretability with predictive performance\n \nDeploying such models can help educators identify students who may benefit from additional support early, improving academic outcomes.","metadata":{}}]}